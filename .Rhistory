pdInfo = subset(sigInfo, pert_id == pert & pert_dose >= dose_ranges[[j]][1]
& pert_dose <= dose_ranges[[j]][2])
if(nrow(pdInfo) > 0){
conductance = as.numeric(C[i, dose_cols[[j]]])
minR = min(conductance, na.rm=TRUE)
#if(!any(is.na(conductance)) && all(conductance > 0.8)){
if(!is.na(minR) && minR > 0.8){
pd = paste(pert, doses[j], sep='_')
# average signature
meanSigs$none[[pd]] = apply(S$lg$none[rownames(pdInfo),], 2, mean)
meanSigs$batch[[pd]] = apply(S$lg$batch[rownames(pdInfo),], 2, mean)
meanSigs$both[[pd]] = apply(S$lg$both[rownames(pdInfo),], 2, mean)
# get metadata: cell_ids, pert_doses, and outcomes
info = rbind(info, c(pert, doses[j], conductance[1], conductance[2], mean(conductance, na.rm=TRUE)))
# store extended metadata for reference
allInfo[[pd]] = pdInfo
}
}
}
}
info = info[-1,]
info
minR
meanSigs = list()
allInfo = list()
info = data.frame(pert_id=NA, cell_id=NA, outcome_dmso=NA, outcome_c18=NA, mean_response=NA)
for(i in 1:length(drugData$metadata$pert_id)){
pert = drugData$metadata$pert_id[i]
print(pert)
for(j in 1:3){
pdInfo = subset(sigInfo, pert_id == pert & pert_dose >= dose_ranges[[j]][1]
& pert_dose <= dose_ranges[[j]][2])
if(nrow(pdInfo) > 0){
conductance = as.numeric(C[i, dose_cols[[j]]])
minR = min(conductance, na.rm=TRUE)
#if(!any(is.na(conductance)) && all(conductance > 0.8)){
if(is.finite(minR) && minR > 0.8){
pd = paste(pert, doses[j], sep='_')
# average signature
meanSigs$none[[pd]] = apply(S$lg$none[rownames(pdInfo),], 2, mean)
meanSigs$batch[[pd]] = apply(S$lg$batch[rownames(pdInfo),], 2, mean)
meanSigs$both[[pd]] = apply(S$lg$both[rownames(pdInfo),], 2, mean)
# get metadata: cell_ids, pert_doses, and outcomes
info = rbind(info, c(pert, doses[j], conductance[1], conductance[2], mean(conductance, na.rm=TRUE)))
# store extended metadata for reference
allInfo[[pd]] = pdInfo
}
}
}
}
info = info[-1,]
warnings()
info
S$sm = lapply(meanSigs, function(x){out = laply(x, identity); rownames(out) = names(x); return(out)})
rownames(S$sm)
rownames(S$sm$none)
dim(info)
rownames(info) = rownames(S$sm$none)
info
# Identify relevant experiments (measured drug/dose combinations with conductance not too low)
C = drugData$outcomes
dose_cols = list(c('1uM_mean.dmso', '1uM_mean.c18'),
c('3uM_mean.dmso', '3uM_mean.c18'),
c('10uM_mean.dmso', '10uM_mean.c18'))
dose_ranges = list(c(0.7,1.3), c(2.1, 3.9), c(7,13))
doses = c('1uM', '3uM', '10uM')
meanSigs = list()
allInfo = list()
info = data.frame(pert_id=NA, dose=NA, outcome_dmso=NA, outcome_c18=NA, mean=NA, max=NA)
for(i in 1:length(drugData$metadata$pert_id)){
pert = drugData$metadata$pert_id[i]
print(pert)
for(j in 1:3){
pdInfo = subset(sigInfo, pert_id == pert & pert_dose >= dose_ranges[[j]][1]
& pert_dose <= dose_ranges[[j]][2])
if(nrow(pdInfo) > 0){
conductance = as.numeric(C[i, dose_cols[[j]]])
minR = min(conductance, na.rm=TRUE)
#if(!any(is.na(conductance)) && all(conductance > 0.8)){
if(is.finite(minR) && minR > 0.8){
pd = paste(pert, doses[j], sep='_')
# average signature
meanSigs$none[[pd]] = apply(S$lg$none[rownames(pdInfo),], 2, mean)
meanSigs$batch[[pd]] = apply(S$lg$batch[rownames(pdInfo),], 2, mean)
meanSigs$both[[pd]] = apply(S$lg$both[rownames(pdInfo),], 2, mean)
# get metadata: cell_ids, pert_doses, and outcomes
info = rbind(info, c(pert_id=pert, dose=doses[j],
outcome_dmso=conductance[1], outcome_c18=conductance[2],
mean=mean(conductance, na.rm=TRUE), max=max(conductance, na.rm=TRUE)))
# store extended metadata for reference
allInfo[[pd]] = pdInfo
}
}
}
}
# Some post-processing
S$sm = lapply(meanSigs, function(x){out = laply(x, identity); rownames(out) = names(x); return(out)})
info = info[-1,]
rownames(info) = rownames(S$sm$none)
?ifelse
# Binarize outcomes in info:
info$result = 'inconclusive'
info$result[info$max >= 1.25] = 'active'
info$result[info$max < 1.2] = 'inactive'
info
varPart = fitExtractVarPartModel(S$sm$none, ~outcome_dmso , info)
dim(S$sm$none)
dim(info)
fitExtractVarPartModel
?fitExtractVarPartModel
S$sm$none
dim(S$sm$none)
varPart = fitExtractVarPartModel(t(S$sm$none), ~outcome_dmso, info)
dim(t(S$sm$none))
head(info)
info$outcome_dmso
lapply(info, class)
meanSigs = list()
allInfo = list()
fill = -999
info = data.frame(pert_id=NA, dose=NA, outcome_dmso=fill, outcome_c18=fill, mean=fill, max=fill)
for(i in 1:length(drugData$metadata$pert_id)){
pert = drugData$metadata$pert_id[i]
print(pert)
for(j in 1:3){
pdInfo = subset(sigInfo, pert_id == pert & pert_dose >= dose_ranges[[j]][1]
& pert_dose <= dose_ranges[[j]][2])
if(nrow(pdInfo) > 0){
conductance = as.numeric(C[i, dose_cols[[j]]])
minR = min(conductance, na.rm=TRUE)
#if(!any(is.na(conductance)) && all(conductance > 0.8)){
if(is.finite(minR) && minR > 0.8){
pd = paste(pert, doses[j], sep='_')
# average signature
meanSigs$none[[pd]] = apply(S$lg$none[rownames(pdInfo),], 2, mean)
meanSigs$batch[[pd]] = apply(S$lg$batch[rownames(pdInfo),], 2, mean)
meanSigs$both[[pd]] = apply(S$lg$both[rownames(pdInfo),], 2, mean)
# get metadata: cell_ids, pert_doses, and outcomes
info = rbind(info, c(pert_id=pert, dose=doses[j],
outcome_dmso=conductance[1], outcome_c18=conductance[2],
mean=mean(conductance, na.rm=TRUE), max=max(conductance, na.rm=TRUE)))
# store extended metadata for reference
allInfo[[pd]] = pdInfo
}
}
}
}
# Some post-processing
S$sm = lapply(meanSigs, function(x){out = laply(x, identity); rownames(out) = names(x); return(out)})
info = info[-1,]
rownames(info) = rownames(S$sm$none)
# Binarize outcomes in info:
info$result = 'inconclusive'
info$result[info$max >= 1.25] = 'active'
info$result[info$max < 1.2] = 'inactive'
varPart = fitExtractVarPartModel(t(S$sm$none), ~outcome_dmso, info)
info$outcome_dmso
info$max
class(info)
info$max >= 1.25
lapply(info, class)
tmp = info
cols = c('outcome_dmso', 'outcome_c18', 'mean', 'max', 'result')
info[,cols] = lapply(info[,cols], as.numeric)
info
info = tmp
tmp
info
cols = c('outcome_dmso', 'outcome_c18', 'mean', 'max')
info[,cols] = lapply(info[,cols], as.numeric)
info
info$outcome_dmso
varPart = fitExtractVarPartModel(t(S$sm$none), ~outcome_dmso, info)
vp = sortCols(varPart)
vp
varPart
vp = varPart
vp[order(vp$outcome_dmso),]
vp[order(vp$outcome_dmso, decreasing=TRUE),]
vp[order(vp$outcome_dmso, decreasing=TRUE)[1:30],]
vp = sortCols(varPart)
plotPercentBars(vp[order(vp$outcome_dmso,decreasing=TRUE)[1:30],])
plotVarPart(vp)
plotVarPart(vp[,1])
vp[,1]
hist(varPart$outcome_dmso)
head(info)
v_dmso = varPart
v_c18 = fitExtractVarPartModel(t(S$sm$none), ~outcome_c18, info)
hist(v_c18)
hist(v_c18$outcome_c18)
cor(v_c18$outcome_c18, v_dmso$outcome_dmso)
plot(v_c18$outcome_c18, v_dmso$outcome_dmso)
v_mean = fitExtractVarPartModel(t(S$sm$none), ~mean, info)
v_max = fitExtractVarPartModel(t(S$sm$none), ~max, info)
info_sub = subset(info, result %in% c('active', 'inactive'))
info_sub
A = S$sm$none[rownames(info_sub),]
dim(A)
dim(S$sm$none)
v_bin = fitExtractVarPartModel(t(A), ~result, info_sub)
V = data.frame(dmso=v_dmso$outcome_dmso, c18=v_c18$outcome_c18,
mean=v_mean$mean, max=v_max$max, binary=v_bin$result)
plotVarPart(V)
?sample
sample(nrow(info))
sample(nrow(info), replace=FALSE)
set.seed(123)
set.seed(123)
v_rand = list()
for(i in 1){
info_shuf = info[sample(nrow(info)),]
v_rand[[i]] = fitExtractVarPartModel(t(S$sm$none), ~outcome_c18, info_shuf)
}
hist(v_rand[[i]]$outcome_c18)
V$rand1 = v_rand[[1]]$outcome_c18
plotVarPart(V)
cor(V$dmso, V$rand1)
cor(V$dmso, V$c18)
for(i in 2){
info_shuf = info[sample(nrow(info)),]
v_rand[[i]] = fitExtractVarPartModel(t(S$sm$none), ~outcome_c18, info_shuf)
}
V[[paste0('rand', str(i))]] = v_rand[[i]]$outcome_c18
plotVarPart(V)
cor(V$rand1, V$rand)
cor(V$binary, V$dmso)
paste0('rand', str(i))
paste0('rand', i)
names(V)
save(V, OutputDir('active_v_inactive/variance_partition_take1.RData'))
save(V, file=OutputDir('active_v_inactive/variance_partition_take1.RData'))
minCutoff = .5
ggsave(file=PlotDir(sprintf('varPart_%0.2fcutoff_no_correction.pdf', 0.8)))
plotVarPart(V, main='Percent of explained variance per gene, no batch correction')
plotVarPart(V, main=sprintf('No batch correction, min cutoff = %0.2f', 0.8))
ggsave(file=PlotDir(sprintf('varPart_%0.2fcutoff_no_correction.pdf', 0.8)))
dir = OutputDir('active_v_inactive')
minCutoff = .5
source('~/Box Sync/CFDR/cfdr/code/R/scripts/compare_sigs/get_relevant_L1000_sigs_for_CF_active_inactive_analysis.R')
A = data.frame(x=0)
A$y = rep(1, 10)
A
dim(S$sm)
dim(S$sm$none)
?gage
library(gage)
?gage
knitr::opts_knit$set(root.dir = '../../')
nPos = length(which(Rmeas$diff > 0))
Rneas
head(Rmeas)
source('~/.active-rstudio-document', echo=TRUE)
getwd()
setwd('~/Desktop/Research/LINCS/submission/dgc_predict')
load('../results/classification/2017-07-30-03-47-00/results_ROC_counts_params.RData')
# Melt AUC results
R = melt(ROC)
names(R) = c('AUC', 'eval', 'model', 'subset', 'feature', 'outcome')
# Split outcome into outcome and category
R = SplitOutcome(R)
# Subset to top three represented ATCs
R = subset(R, outcome %in% c('L','C','D') | category == 'Target')
# Subset to evaluations on measured signatures and reformat data
Rmeas = RemoveDfColumns(subset(R, eval == 'eval_meas'), 'eval')
Rmeas$AUC[is.na(Rmeas$AUC)] = 0.5
Rmeas = dcast(Rmeas, model + feature + outcome + category ~ subset, value.var='AUC')
Rmeas = suppressWarnings(ChangeColumnName(Rmeas, from=c('full','obs'), to=c('AUC.full', 'AUC.obs')))
Rmeas$diff = Rmeas$AUC.full - Rmeas$AUC.obs
idx = Rmeas$category == 'ATC'
Rmeas$outcome[idx] = paste0('ATC ' , Rmeas$outcome[idx])
# Results where AUCs were both below this in the two comparisons are thrown out
threshold = 0.5
Rmeas = FilterByAUC(Rmeas, threshold)
t.test(x=Rmeas$AUC.full, y=Rmeas$AUC.obs, paired=TRUE)
nPos = length(which(Rmeas$diff > 0))
nTot = nrow(Rmeas)
print(sprintf('%d out of %d increased AUC', nPos, nTot))
print(ggplot(Rmeas, aes(x=model, y=diff, group=model, fill=model)) + geom_boxplot() + ggtitle('Improvement in AUC per model') + stat_compare_means())
print(lapply(split(Rmeas, Rmeas$model), function(x) t.test(x$AUC.full, x$AUC.obs, paired=TRUE)))
numSigs = c(MCF7=1505, VCAP=1368, PC3=1340, A375=1168, A549=1139,
HA1E=1127, HT29=1022, HCC515=934, HEPG2=798, NPC=441)
Rmeas$num_sigs = numSigs[Rmeas$feature]
p_feature = sapply(split(Rmeas, Rmeas$feature), function(x) t.test(x$AUC.full, x$AUC.obs, paired=TRUE)$p.value)
adjp_feature = p.adjust(p_feature, method='BH')
ggplot(melt(Rmeas), aes(x=reorder(feature, -diff, FUN=median), y=diff, group=feature, fill=num_sigs)) +  geom_hline(yintercept = 0, color='grey', lwd=1) +
geom_boxplot(alpha=0.9) +
ggtitle(sprintf('Deltas per feature, threshold = %0.1f', threshold)) +
theme_bw() + ylim(c(-0.5,0.5)) + scale_fill_gradientn(colours=brewer.pal(5,'YlOrRd')) +
theme(text = element_text(size=18), axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(size=20, hjust=0.5),
legend.justification='bottom', legend.position='bottom') +
labs(fill='# Signatures  \n  Measured\n', x='', y=expression(AUC [impute] - AUC [orig]),
title='Improvement in AUC per Drug Signature Type')
head(Rmeas)
numSigs = c(MCF7=1505, VCAP=1368, PC3=1340, A375=1168, A549=1139,
HA1E=1127, HT29=1022, HCC515=934, HEPG2=798, NPC=441)
Rmeas$num_sigs = numSigs[Rmeas$feature]
p_feature = sapply(split(Rmeas, Rmeas$feature), function(x) t.test(x$AUC.full, x$AUC.obs, paired=TRUE)$p.value)
adjp_feature = p.adjust(p_feature, method='BH')
ggplot(melt(Rmeas), aes(x=reorder(feature, diff, FUN=median), y=diff, group=feature, fill=num_sigs)) +  geom_hline(yintercept = 0, color='grey', lwd=1) +
geom_boxplot(alpha=0.9) +
ggtitle(sprintf('Deltas per feature, threshold = %0.1f', threshold)) +
theme_bw() + ylim(c(-0.5,0.5)) + scale_fill_gradientn(colours=brewer.pal(5,'YlOrRd')) +
theme(text = element_text(size=18), axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(size=20, hjust=0.5),
legend.justification='bottom', legend.position='bottom') +
labs(fill='# Signatures  \n  Measured\n', x='', y=expression(AUC [impute] - AUC [orig]),
title='Improvement in AUC per Drug Signature Type')
head(Rmeas)
dim(Rmeas)
any(is.na(Rmeas))
any(is.na(Rmeas$feature))
any(is.na(Rmeas$diff))
ggplot(Rmeas, aes(x=reorder(feature, -diff, FUN=median), y=diff, group=feature, fill=num_sigs)) +  geom_hline(yintercept = 0, color='grey', lwd=1) +
geom_boxplot(alpha=0.9) +
ggtitle(sprintf('Deltas per feature, threshold = %0.1f', threshold)) +
theme_bw() + ylim(c(-0.5,0.5)) + scale_fill_gradientn(colours=brewer.pal(5,'YlOrRd')) +
theme(text = element_text(size=18), axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(size=20, hjust=0.5),
legend.justification='bottom', legend.position='bottom') +
labs(fill='# Signatures  \n  Measured\n', x='', y=expression(AUC [impute] - AUC [orig]),
title='Improvement in AUC per Drug Signature Type')
p_feature = sapply(split(Rmeas, Rmeas$feature), function(x) t.test(x$AUC.full, x$AUC.obs, paired=TRUE)$p.value)
adjp_feature = p.adjust(p_feature, method='BH')
adjp_feature
sort(adjp_feature)
ATC = subset(RC, category=='ATC' & outcome %in% c('L','C','D'))
load('../results/classification/2017-07-30-03-47-00/results_ROC_counts_params.RData')
load(ResultsDir('classification/2017-07-30-03-47-00/RC.RData'))
source('~/.active-rstudio-document', echo=TRUE)
ATC
source('~/Desktop/Research/LINCS/submission/dgc_predict/R/applications/compute_AUCs_on_imputed_signatures.R')
source('~/Desktop/Research/LINCS/submission/dgc_predict/R/applications/compute_AUCs_on_imputed_signatures.R')
getwd()
source('R/src/Utils.R')
source('R/src/DataProc.R')
load('../results/classification/2017-07-30-03-47-00/results.RData')
load('../results/classification/2017-07-30-03-47-00/RC.RData')
ATC = subset(RC, category=='ATC' & outcome %in% c('L','C','D'))
Targets = subset(RC, category == 'Target')
save(RC, ATC, Targets, file=ResultsDir('classification/2017-07-30-03-47-00/RC.RData'))
dim(Rmeas)
ddply(Rmeas, 'outcome', summarize, median, .variables='diff')
?ddply
ddply(Rmeas, 'outcome', function(x) median(x$diff), 'summarize')
ddply(Rmeas, 'outcome', summarise, median.diff= median(diff))
t.test(Targets$AUC_imp, Targets$AUC_meas, paired=TRUE)
t.test(ATC$AUC_imp, ATC$AUC_meas, paired=TRUE)
dim(RC)
head(RC)
RC$nPos_imp
hist(RC$nPos_imp)
hist(RC$nPos_imp, breaks=20)
hist(RC$nPos_imp, breaks=40)
plot(RC$nPos_imp, RC$nPos_meas)
source('~/Desktop/Research/LINCS/submission/dgc_predict/R/applications/compute_AUCs_on_imputed_signatures.R')
ggplot(RC, aes(x=nPos_imp, y=nPos_meas, fill=outcome)) + geom_point()
ggplot(RC, aes(x=nPos_imp, y=nPos_meas, color=outcome)) + geom_point()
rm(list=ls())
testAll = FALSE; source('R/init.R')
source('~/Desktop/Research/LINCS/submission/dgc_predict/R/applications/analyze_AUCimp_v_AUCmeas.R')
dim(ATC)
dim(Targets)
ATC
ATC$outcome
dim(ATC)
dim(Targets)
head(Targets)
tar = subset(Targets, AUC_imp > 0.5 | AUC_meas > 0.5 )
dim(tar)
dim(Targets)
RC = merge(R, C, all=TRUE, by=c('outcome','feature'))
RC = subset(RC, nPos_imp >= 3 & nPos_meas >= 3)
RC = merge(R, C, all=TRUE, by=c('outcome','feature'))
RC = merge(R, C, all=TRUE, by=c('outcome','feature'))
dim(RC)
RC = subset(RC, category=='Target' | outcome %in% c('L','C','D'))
dim(RC)
RC = subset(RC, AUC_imp > 0.5 | AUC_meas > 0.5 )
dim(RC)
RC = merge(R, C, all=TRUE, by=c('outcome','feature'))
RC = subset(RC, category=='Target' | outcome %in% c('L','C','D'))
print(sprintf('Starting with %d experiments', nrow(RC)))
RC = subset(RC, AUC_imp > 0.5 | AUC_meas > 0.5 )
print(sprintf('After filtering by AUC > 0.5, %d experiments remaining', nrow(RC)))
RC = subset(RC, nPos_imp >= 3 & nPos_meas >= 3)
print(sprintf('After filtering by num labels >= 3, %d experiments remaining', nrow(RC)))
Targets = subset(RC, category == 'Target')
ATC = subset(RC, category == 'ATC')
save(RC, ATC, Targets, file=ResultsDir('classification/2017-07-30-03-47-00/RC_all_models.RData'))
dim(ATC)
dim(Targets)
197+87
t.test(ATC$AUC_imp, ATC$AUC_meas, paired=TRUE)
t.test(Targets$AUC_imp, Targets$AUC_meas, paired=TRUE)
dim(RC)
subset(RC, feature == 'PC')
dim(RC)
subset(RC, feature == 'PC3')
subset(RC, feature == 'PC3' & outcome == 'RORC')
ggplot(ATC, aes(x=AUC_meas, y=AUC_imp, color=outcome, label=feature)) +
geom_abline(slope=1, intercept=0, color='DarkGrey', lty='dashed') + geom_point(size=7, alpha=0.6) +
xlim(c(0,1)) + ylim(c(0,1)) +
geom_text(size=3, color='black', check_overlap=TRUE) + theme_bw() +
guides(color=guide_legend(title='ATC Code')) +
xlab('AUC on measured signatures') + ylab('AUC on predicted signatures') +
theme(axis.text=element_text(size=12), axis.title=element_text(size=18),
legend.text=element_text(size=10), legend.title=element_text(size=10),
legend.position='bottom', legend.justification='bottom')
ggsave(PlotDir('ATC_code_imputed_vs_measured.svg'), width=9, height=7)
ggplot(Targets, aes(x=AUC_meas, y=AUC_imp, color=outcome, label=feature)) +
geom_abline(slope=1, intercept=0, color='DarkGrey', lty='dashed') + geom_point(size=7, alpha=0.6) +
xlim(c(0,1)) + ylim(c(0,1)) +
geom_text(size=3, color='black', check_overlap=TRUE) + theme_bw() + guides(color=guide_legend(title='Target')) +
xlab('AUC on measured signatures') + ylab('AUC on predicted signatures') +
theme(axis.text=element_text(size=12), axis.title=element_text(size=18),
legend.text=element_text(size=10), legend.title=element_text(size=10),
legend.position='bottom', legend.justification='bottom')
ggsave(PlotDir('Target_imputed_vs_measured.svg'), width=9, height=7)
ggplot(Targets, aes(x=AUC_meas, y=AUC_imp, color=outcome, label=feature)) +
geom_abline(slope=1, intercept=0, color='DarkGrey', lty='dashed') + geom_point(size=7, alpha=0.6) +
xlim(c(0,1)) + ylim(c(0,1)) +
geom_text(size=3, color='black', check_overlap=TRUE) + theme_bw() + guides(color=guide_legend(title='Target', nrow=1)) +
xlab('AUC on measured signatures') + ylab('AUC on predicted signatures') +
theme(axis.text=element_text(size=12), axis.title=element_text(size=18),
legend.text=element_text(size=10), legend.title=element_text(size=10),
legend.position='bottom', legend.justification='bottom')
ggsave(PlotDir('Target_imputed_vs_measured.svg'), width=9, height=7)
ggplot(ATC, aes(x=AUC_meas, y=AUC_imp, color=outcome, label=feature)) +
geom_abline(slope=1, intercept=0, color='DarkGrey') + geom_point(size=7, alpha=0.6) +
geom_hline(yintercept=0.5, color='DarkGrey', lty='dashed') +
geom_vline(xintercept=0.5, color='DarkGrey', lty='dashed') +
xlim(c(0,1)) + ylim(c(0,1)) +
geom_text(size=3, color='black', check_overlap=TRUE) + theme_bw() +
guides(color=guide_legend(title='ATC Code', nrow =1)) +
xlab('AUC on measured signatures') + ylab('AUC on predicted signatures') +
theme(axis.text=element_text(size=12), axis.title=element_text(size=18),
legend.text=element_text(size=10), legend.title=element_text(size=10),
legend.position='bottom', legend.justification='bottom')
ggsave(PlotDir('ATC_code_imputed_vs_measured.svg'), width=8, height=7)
ggplot(ATC, aes(x=AUC_meas, y=AUC_imp, color=outcome, label=feature)) +
geom_abline(slope=1, intercept=0, color='DarkGrey', lty='dashed') + geom_point(size=7, alpha=0.6) +
geom_hline(yintercept=0.5, color='DarkGrey') +
geom_vline(xintercept=0.5, color='DarkGrey') +
xlim(c(0,1)) + ylim(c(0,1)) +
geom_text(size=3, color='black', check_overlap=TRUE) + theme_bw() +
guides(color=guide_legend(title='ATC Code', nrow =1)) +
xlab('AUC on measured signatures') + ylab('AUC on predicted signatures') +
theme(axis.text=element_text(size=12), axis.title=element_text(size=18),
legend.text=element_text(size=10), legend.title=element_text(size=10),
legend.position='bottom', legend.justification='bottom')
ggsave(PlotDir('ATC_code_imputed_vs_measured.svg'), width=8, height=7)
ggplot(ATC, aes(x=AUC_meas, y=AUC_imp, color=outcome, label=feature)) +
geom_abline(slope=1, intercept=0, color='DarkGrey') + geom_point(size=7, alpha=0.6) +
xlim(c(0,1)) + ylim(c(0,1)) +
geom_text(size=3, color='black', check_overlap=TRUE) + theme_bw() +
guides(color=guide_legend(title='ATC Code', nrow =1)) +
xlab('AUC on measured signatures') + ylab('AUC on predicted signatures') +
theme(axis.text=element_text(size=12), axis.title=element_text(size=18),
legend.text=element_text(size=10), legend.title=element_text(size=10),
legend.position='bottom', legend.justification='bottom')
ggsave(PlotDir('ATC_code_imputed_vs_measured.svg'), width=8, height=7)
ggplot(ATC, aes(x=AUC_meas, y=AUC_imp, color=outcome, label=feature)) +
geom_abline(slope=1, intercept=0, color='DarkGrey', lty='dashed') + geom_point(size=7, alpha=0.6) +
xlim(c(0,1)) + ylim(c(0,1)) +
geom_text(size=3, color='black', check_overlap=TRUE) + theme_bw() +
guides(color=guide_legend(title='ATC Code', nrow =1)) +
xlab('AUC on measured signatures') + ylab('AUC on predicted signatures') +
theme(axis.text=element_text(size=12), axis.title=element_text(size=18),
legend.text=element_text(size=10), legend.title=element_text(size=10),
legend.position='bottom', legend.justification='bottom')
ggsave(PlotDir('ATC_code_imputed_vs_measured.svg'), width=8, height=7)
ggplot(Targets, aes(x=AUC_meas, y=AUC_imp, color=outcome, label=feature)) +
geom_abline(slope=1, intercept=0, color='DarkGrey', lty='dashed') + geom_point(size=7, alpha=0.6) +
xlim(c(0,1)) + ylim(c(0,1)) +
geom_text(size=3, color='black', check_overlap=TRUE) + theme_bw() + guides(color=guide_legend(title='Target', nrow=1)) +
xlab('AUC on measured signatures') + ylab('AUC on predicted signatures') +
theme(axis.text=element_text(size=12), axis.title=element_text(size=18),
legend.text=element_text(size=10), legend.title=element_text(size=10),
legend.position='bottom', legend.justification='bottom')
ggsave(PlotDir('Target_imputed_vs_measured.svg'), width=8, height=7)
n=load(ResultsDir('classification/2017-07-30-03-47-00/RC_all_models.RData'))
n
dim(RC)
dim(Targets)
tar = subset(Targets, feature =='HT29')
dim(tar)
tar
RC$diff = RC$AUC_imp - RC$AUC_meas
r = subset(RC, diff > 0)
r
unique(r$outcome)
length(unique(r$outcome))
r
r$outcome
sort(r$outcome)
s = subset(RC, diff < 0)
dim(RC)
sort(s$outcome)
A = subset(RC, feature == 'HT29')
dim(A)
A
A = subset(RC, feature == 'HT29' & category == 'Target')
dim(A)
A
hist(A$diff)
mean(A$diff)
dim(A)
H = A
mean(H$AUC_imp - H$AUC_meas)
print(sprintf('mean improvement by HT29 imputed signatures: %0.2f', mean(H$AUC_imp - H$AUC_meas)))
